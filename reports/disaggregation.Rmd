---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: false
    fig_caption: true
    latex_engine: pdflatex
title: Borrowing information across spatial scales 
author:
- name: Sangeeta Bhatia
  affiliation: Imperial College London
abstract: 
keywords: 
date: "Y"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
spacing: double
bibliography: 
biblio-style: apsr
endnote: no
params:
  pow_dist : 1
  from : KONO
  n.sim : 1000
  n.dates.sim : 49
  p.stay: 0.9
  ADM0: SIERRALEONE
  bin_from: 2015-W01
---

```{r global_options, include=FALSE}

knitr::opts_chunk$set(
  fig.width = 12, fig.height = 6,
  echo = FALSE,
  warning = FALSE, message = FALSE,
  fig.path = "figures/"
)
```

```{r setup, eval = TRUE}

library(dplyr)
library(stringr)
library(ggplot2)
library(purrr)
library(EpiEstim)
devtools::load_all()
```

## Unpack parameters

```{r pars_read, eval = TRUE}

pow_dist <- params$pow_dist
t.proj <- params$t.proj
n.sim <- params$n.sim
n.dates.sim <- params$n.dates.sim
p.stay <- params$p.stay
adm0 <- params$ADM0
from <- params$from
bin_from <- params$bin_from
method <- list(
  "pop_density" = FALSE,
  "gm" = FALSE,
  "restim" = TRUE,
  "epiestim" = FALSE
)
```

## Model

We will assign the national case count to districts according to a
multinomial distribution with the probabilities derived from gravity
model or simply population density. 

First we read in the data that is required by both methods.

## Ebola Parameters
```{r ebola_params}

mean_SI <- 14.2
CV_SI <- 9.6 / 14.2
SItrunc <- 40
SI_Distr <- sapply(0:SItrunc, function(e) DiscrSI(e, mean_SI, mean_SI * CV_SI))
SI_Distr <- SI_Distr / sum(SI_Distr)
```

## Districts meta-data

```{r districts_coord, eval = TRUE}

centroids <- here::here(
  "data/Geography/GravityModel/processed",
  "all_centroids.csv"
) %>%
  readr::read_csv(.) %>%
  filter(ADM0 == adm0)
```

## Incidence data from HealthMap
This is the aggregated data that will be used to assign cases to
districts.

```{r hm_data, eval = TRUE}

hm_wide <- here::here(
  "data/CaseCounts/processed",
  "HealthMap_Ebola_wide.csv"
) %>%
  readr::read_csv(.)
```  

We will work with weekly incidence counts. 

```{r hm_weekly, eval = TRUE}

hm_weekly <- daily.to.weekly(hm_wide)
```
Also add isoweek column so that we can compare across the three data
sets.

```{r}
hm_weekly$week_of_year <- paste0(lubridate::year(hm_weekly$Date),
                            "-W",
                            stringr::str_pad(lubridate::isoweek(hm_weekly$Date),
                                             2,
                                             pad = "0"))

hm_weekly$week_of_year <- factor(hm_weekly$week_of_year, ordered = TRUE)
```
## Weekly Training Incidence Data 

```{r, eval = method[["restim"]]}
who_wide <- here::here("data/CaseCounts/processed",
                       "who_sitrep_wide_sl_2016-05-11.csv") %>%
    readr::read_csv()
who_wide$week_of_year <- factor(who_wide$week_of_year, ordered = TRUE)
```

## Validation data

The performance of the model will be validated against the cleaned-up
data.


```{r who, eval = TRUE}

sl_weekly <- here::here(
  "data/CaseCounts/processed",
  "sl_weekly_tall.csv"
) %>%
  readr::read_csv(.) 

sl_weekly$week_of_year <- paste0(lubridate::year(sl_weekly$Date),
                            "-W",
                            stringr::str_pad(lubridate::isoweek(sl_weekly$Date),
                                      2,
                                      pad = "0"))
```

## Method 1: Relative population density

Take the weekly incidence
count and distribute it to the districts in proportion to their
relative density.

```{r pop_density, eval = method[["pop_density"]]}

pop_density <- data.frame(
  district = centroids$CL_DistrictRes,
  rel_density = centroids$pop / sum(centroids$pop)
)
prob <- matrix(pop_density$rel_density ^ 2, nrow = 1)
colnames(prob) <- pop_density$district
```

## Method 2: Relative risk based on gravity model


```{r pmovement, eval = method[["gm"]]}
flow_mat <- flow_matrix(
  longitude = centroids$lon,
  latitude = centroids$lat,
  population = centroids$pop,
  place_names = centroids$CL_DistrictRes,
  model = "gravity", K = K,
  pow_N_from = pow_N_from,
  pow_N_to = pow_N_to,
  pow_dist = pow_dist
)
rel_risk <- flow_mat / rowSums(flow_mat, na.rm = TRUE)
p_movement <- probability_movement(rel_risk, p_stay)
prob <- p_movement[from, ]
```
## Method 3: Relative to the reproduction number from recent past

### 3A: Use data published by WHO

Suppose we are doing the disaggregation in the last week of 2014.
Read in the latest information published by WHO.
Start binning at date that ends week in variable ``bin_from''.
It might be better to use recent data rather than all data
available upto the point of projection.

```{r}
use_last <- 6 ## weeks data
trng_end_level <- which(levels(who_wide$week_of_year) == bin_from)
trng_start_level <- if (trng_end_level < (use_last + 1)) 1 else trng_end_level - use_last
trng_start <- levels(who_wide$week_of_year)[trng_start_level]
trng_end <- bin_from
who_wide <- filter(
  who_wide,
  week_of_year >= trng_start,
  week_of_year <= trng_end
)
```

## Fitting log-linear model

```{r}
ll_fit <- select_if(who_wide, is.numeric) %>%
    map(function(I){
        incid <- incidence::as.incidence(x = I,
                                         interval = 7,
                                         isoweek = TRUE)
        incidence::fit(incid)
    })

district_rates <- map(ll_fit, function(fit){
    epitrix::r2R0(fit$info$r, SI_Distr)})
```

## 3B: Use cleaned-up linelist

```{r sl_ll, eval = method[["epiestim"]]}
who_wide <- here::here(
  "data/CaseCounts/processed",
  "SIERRALEONE_wide.csv"
) %>%
  readr::read_csv(.)
```

Estimate R using EpiEstim.
Use incidence data till 3rd week of December 2014 and use the
estimated R value to bin national count in the last week of 2014 into
districts.


```{r epistim,  eval = method[["epiestim"]]}
who_wide <- filter(who_wide, Date < "2014-12-15")
time_window <- 49
start <- 2:(nrow(who_wide) - time_window)
end <- start + time_window
r.estim <- select_if(who_wide, is.numeric) %>%
  map(function(I) {
    res <- EpiEstim::EstimateR(
      I,
      T.Start = start,
      T.End = end,
      method = "NonParametricSI",
      SI.Distr = SI_Distr,
      plot = FALSE,
      CV.Posterior = 1,
      Mean.Prior = 1,
      Std.Prior = 0.5
    )
    res$R[nrow(res$R), ]
  })
```

What we have is a full posterior distribution of R. Ideally we should
draw samples and not use a point estimate.

```{r draw_samples,  eval = method[["epiestim"]]}
n.sim <- 1
prob <- map_dfc(r.estim, function(x) {
  shape <- x$"Mean(R)" ^ 2 / x$"Std(R)" ^ 2
  scale <- x$"Std(R)" ^ 2 / x$"Mean(R)"
  rgamma(n.sim, shape = shape, scale = scale)
})
```

## Estimate R 

						 
```{r restim, eval = method[["restim"]]}

r.estim <- select_if(who_wide, is.numeric) %>%
  map(function(x) {
    df <- data.frame(t = seq_len(length(x)), incid = x)
    glm(incid ~ t, data = df, family = poisson())
  })


## check fit
predicted <- map(r.estim, predict, type = "response") %>%
  dplyr::bind_cols(.)

predicted$week_of_year <- who_wide$week_of_year

list(predicted = predicted, observed = who_wide) %>%
  dplyr::bind_rows(.id = "data_source") %>%
  tidyr::gather(district, incid, -week_of_year, -data_source) %>%
  ggplot(aes(week_of_year, incid, col = data_source)) + geom_point() +
  facet_wrap(~district, scale = "free_y")
```

Extract the coefficients from the fits.

```{r,  eval = method[["restim"]]}
district_rates <- map_dfr(r.estim, function(x) exp(coef(x)["t"]))
#district_rates <- map_dfr(r.estim, function(x){
#    r <- exp(coef(x)["t"])
#    epitrix::r2R0(r, SI_Distr)
#})
prob <- matrix(unlist(district_rates), nrow = 1)
colnames(prob) <- colnames(who_wide)[-1]
```
## Assign cases to districts

```{r write_probs, eval = FALSE}

prob_df <- data.frame(prob) %>% tidyr::gather(district, prob)
prob_df$rel_prob <- prob_df$prob / sum(prob_df$prob)
prob_df <- arrange(prob_df, district)
paste0(names(method)[which(method == TRUE)], "_probs.csv") %>%
  readr::write_csv(x = prob_df, path = .)
```

Extract the data we want to use for disaggreation.

```{r}
bin_for <- 6 ## weeks
num_weeks <- length(levels(hm_weekly$week_of_year))
start_at <- which(levels(hm_weekly$week_of_year) == bin_from)
end_at <- min(num_weeks, start_at + bin_for)


bin_end   <- levels(hm_weekly$week_of_year)[end_at]

bin_this <- filter(
  hm_weekly,
  week_of_year >= bin_from,
  week_of_year <= bin_end
) %>%
    droplevels() %>%
    select(week_of_year, `Sierra Leone`)
```

						 
```{r assign, eval = TRUE}
district_weekly <- split(bin_this, bin_this$week_of_year) %>%
  lapply(function(df) {
    mat <- disaggregate(
      total = df$`Sierra Leone`,
      pmatrix = prob
    )
    colnames(mat) <- colnames(prob)
    probs <- c(0.025, 0.5, 0.975)
    distr <- disaggregate_distr(mat, probs = probs)
    distr
  }) %>%
  bind_rows(.id = "week_of_year")

district_weekly$bin_from <- bin_from
district_weekly$district <- stringr::str_replace_all(district_weekly$district,
                                                     "PORT.LOKO",
                                                     "PORTLOKO")
```

Write out the output. 

```{r}
method <- names(method)[which(method == TRUE)]
maxdate <- max(district_weekly$Date)

here::here("output", paste0(
 "projections_",                        
  method,
  "_",
  maxdate,
  ".csv"
)) %>%
    readr::write_csv(x = district_weekly, path = .)

```
Also write out the training data.

```{r trng, eval = FALSE}


here::here("output", paste0(
  "training_",                         
  method,
  "_",
  maxdate,
  ".csv"
)) %>%
    readr::write_csv(x = who_wide, path = .)



```

## Visualizing the results

## Validation data

## Training Data
```{r}
who_tall <- tidyr::gather(who_wide, district, incid, -week_of_year)
```

```{r}
compare <- left_join(bin_this, sl_weekly)
compare$week_of_year <- factor(compare$week_of_year)
district_weekly$week_of_year <- factor(district_weekly$week_of_year)
district_weekly$district <- factor(district_weekly$district)
## Plot training data
p <- ggplot(who_tall, aes(week_of_year, incid)) + geom_point(col = "red")
p <- p + facet_wrap(~district, scale = "free_y")

## Plot validation data
p <- p + geom_point(data = compare, aes(x = week_of_year, y = incid))

## Plot projections
p <- p + geom_line(data = district_weekly,
                   aes(x = week_of_year, y = `0.5`, group = 1),
                   col = "blue")
p <- p + geom_ribbon(data = district_weekly,
                     aes(x = week_of_year,
                         ymin = `0.025`,
                         ymax = `0.975`,
                         group = 1),
                     alpha = 0.5,
                     inherit.aes = FALSE)

p <- p + theme_classic()
p

```
