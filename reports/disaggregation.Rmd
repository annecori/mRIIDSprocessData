---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: false
    fig_caption: true
    latex_engine: pdflatex
title: Borrowing information across spatial scales 
author:
- name: Sangeeta Bhatia
  affiliation: Imperial College London
abstract: 
keywords: 
date: "Y"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
spacing: double
bibliography: 
biblio-style: apsr
endnote: no
params:
  pow_dist : 1
  from : KONO
  n.sim : 1000
  n.dates.sim : 49
  p.stay: 0.9
  ADM0: SIERRALEONE
---

```{r global_options, include=FALSE}

knitr::opts_chunk$set(
  fig.width = 12, fig.height = 6,
  echo = FALSE,
  warning = FALSE, message = FALSE,
  fig.path = "figures/"
)
```

```{r setup, eval = TRUE}

library(dplyr)
library(magrittr)
library(stringr)
library(ggplot2)
library(purrr)
library(EpiEstim)
devtools::load_all()
```

## Unpack parameters

```{r pars_read, eval = TRUE}

pow_dist <- params$pow_dist
t.proj <- params$t.proj
n.sim <- params$n.sim
n.dates.sim <- params$n.dates.sim
p.stay <- params$p.stay
adm0 <- params$ADM0
from <- params$from
method <- list("pop_density" = FALSE,
               "gm" = FALSE,
               "restim" = TRUE,
               "epiestim" = FALSE)

```

## Model

We will assign the national case count to districts according to a
multinomial distribution with the probabilities derived from gravity
model or simply population density. 

First we read in the data that is required by both methods.

## Districts meta-data

```{r districts_coord, eval = TRUE}

centroids <- here::here(
  "data/Geography/GravityModel/processed",
  "all_centroids.csv"
) %>%
  readr::read_csv(.) %>%
  filter(ADM0 == adm0)
```

## Incidence data from HealthMap

```{r hm_data, eval = TRUE}

hm_wide <- here::here(
  "data/CaseCounts/processed",
  "HealthMap_Ebola_wide.csv"
) %>%
  readr::read_csv(.)
```  

We will work with weekly incidence counts. 

```{r hm_weekly, eval = TRUE}

hm_weekly <- daily.to.weekly(hm_wide)
```

## Incidence data from WHO

District-level data from WHO to compare our estimates with.


```{r who, eval = TRUE}
cols <- c("Date", centroids$CL_DistrictRes)
who_districts <- here::here(
  "data/CaseCounts/processed",
  "WHO_wide.csv"
) %>%
  readr::read_csv(.) %>%
  select(cols)


who_weekly <- daily.to.weekly(who_districts) %>%
  tidyr::gather(district, incid, -Date)

who_weekly$Date <- as.Date(who_weekly$Date)
```

## Method 1: Relative population density

Take the weekly incidence
count and distribute it to the districts in proportion to their
relative density.

```{r pop_density, eval = method[["pop_density"]]}

pop_density <- data.frame(
  district = centroids$CL_DistrictRes,
  rel_density = centroids$pop / sum(centroids$pop)
)
prob <- matrix(pop_density$rel_density^2, nrow = 1)
colnames(prob) <- pop_density$district
```

## Method 2: Relative risk based on gravity model


```{r pmovement, eval = method[["gm"]]}
flow_mat <- flow_matrix(
  longitude = centroids$lon,
  latitude = centroids$lat,
  population = centroids$pop,
  place_names = centroids$CL_DistrictRes,
  model = "gravity", K = K,
  pow_N_from = pow_N_from,
  pow_N_to = pow_N_to,
  pow_dist = pow_dist
)
rel_risk <- flow_mat / rowSums(flow_mat, na.rm = TRUE)
p_movement <- probability_movement(rel_risk, p_stay)
prob <- p_movement[from, ]
```
## Method 3: Relative to the reproduction number from recent past

### 3A: Use data published by WHO

Suppose we are doing the disaggregation in the last week of 2014.
Read in the latest information published by WHO.

```{r, eval = method[["restim"]]}
who_bydistrict <- here::here("data/CaseCounts/processed",
                             "processed_who_sl_2014-12-17.csv") %>%
    read.csv(.)
weeks <- stringr::str_pad(1:50, 2, pad = "0")
weeks_of_2014 <- paste0("2014-W", weeks)
who_bydistrict$week_of_year <- factor(who_bydistrict$week_of_year,
                                      levels = weeks_of_2014)

who_bydistrict <- arrange(who_bydistrict, week_of_year)

```

Look at the data.

```{r sitrep_viz, eval =  method[["restim"]]}
p <- ggplot(who_bydistrict, aes(week_of_year,
                                new_cases,
                                col = data_source))
p <- p + geom_point()
p <- p + facet_wrap(~location, scale = "free_y")
p <- p + theme_bw()
p <- p + theme(axis.text.x =
                   element_text(angle = 90,
                                hjust = 1,
                                size = 3))
p
```

We will use data from Situation Report and add confirmed and probable 
cases. Treat NAs as 0.

```{r, eval = method[["restim"]]}
who_sitrep <- filter(who_bydistrict,
                     data_source == "situationreport") %>%
    droplevels()

who_sitrep <- group_by(who_sitrep, location, week_of_year) %>%
    summarise(total = sum(new_cases)) 

who_wide <- tidyr::spread(who_sitrep, location, total, fill = 0)
```


## 3B: Use cleaned-up linelist

```{r sl_ll, eval = method[["epiestim"]]}
who_wide <- here::here("data/CaseCounts/processed",
                               "SIERRALEONE_wide.csv") %>%
    readr::read_csv(.) 
```

```{r ebola_params}

mean_SI     <- 14.2
CV_SI       <- 9.6 / 14.2
SItrunc     <- 40
SI_Distr    <- sapply(0:SItrunc, function(e) DiscrSI(e, mean_SI, mean_SI * CV_SI))
SI_Distr    <- SI_Distr / sum(SI_Distr)


```
Estimate R using EpiEstim.
Use incidence data till 3rd week of December 2014 and use the
estimated R value to bin national count in the last week of 2014 into
districts.


```{r epistim,  eval = method[["epiestim"]]}
who_wide <- filter(who_wide, Date < "2014-12-15")
time_window <- 49
start     <- 2:(nrow(who_wide) - time_window)
end       <- start + time_window
r.estim   <- select_if(who_wide, is.numeric)  %>%
    map(function(I) {    
        res <- EpiEstim::EstimateR(I,
                                   T.Start = start ,
                                   T.End = end,
                                   method = "NonParametricSI",
                                   SI.Distr = SI_Distr,
                                   plot = FALSE ,
                                   CV.Posterior = 1 ,
                                   Mean.Prior = 1 ,
                                   Std.Prior = 0.5)
        res$R[nrow(res$R), ]
    })

```

What we have is a full posterior distribution of R. Ideally we should
draw samples and not use a point estimate.

```{r draw_samples,  eval = method[["epiestim"]]}
n.sim <- 1000
prob <- map_dfc(r.estim, function(x){
    shape  <- x$"Mean(R)"^2 / x$"Std(R)"^2
    scale  <- x$"Std(R)"^2 /  x$"Mean(R)"
    rgamma(n.sim, shape = shape, scale = scale)})

```

## Estimate R 

```{r restim, eval = method[["restim"]]}
r.estim   <- select_if(who_wide, is.numeric)  %>%
    map(function(x) {
        df = data.frame(t = seq_len(length(x)), incid = x)
        glm(x ~ t, data = df, family = poisson())
    })

## check fit
predicted <- map(r.estim, predict, type = "response") %>%
    dplyr::bind_cols(.)

predicted$week_of_year <- who_wide$week_of_year

list(predicted = predicted, observed = who_wide) %>%
    dplyr::bind_rows(.id = "data_source") %>%
    tidyr::gather(district, incid, -week_of_year, -data_source) %>%
    ggplot(aes(week_of_year, incid, col = data_source)) + geom_point() +
    facet_wrap(~district, scale = "free_y")



```

Extract the coefficients from the fits.
```{r,  eval = method[["restim"]]}
district_rates <- map_dfr(r.estim, function(x) coef(x)["t"])
prob <- matrix(district_rates, nrow = 1)
colnames(prob) <- colnames(who_wide)[-1]
```
## Assign cases to districts

Best to do it when the number of cases is not too small.
Also, probably not for the whole duration but 2 or 3 weeks.
Furthermore, we have used data for the first 50 weeks of 2014 to
estimate R. So we will do the binning starting week 51 of 2014.

```{r assign, eval = TRUE}
bin_for <- 16 ## weeks
hm_large <- filter(hm_weekly, `Sierra Leone` > 2)
sl_large <- select(hm_large, c(Date, `Sierra Leone`)) %>%
    `[`(seq_len(bin_for), )
district_weekly <- split(sl_large, sl_large$Date) %>%
  lapply(function(df) {
    mat <- disaggregate(
      total = df$`Sierra Leone`,
      pmatrix = prob
    )
    colnames(mat) <- colnames(prob)
    probs <- c(0.025, 0.5, 0.975)
    distr <- disaggregate_distr(mat, probs = probs)
    distr
  }) %>% bind_rows(.id = "Date")
district_weekly$Date <- as.Date(district_weekly$Date)
```


## Compare with data from WHO

Put them together and plot.

```{r compare, eval = TRUE}
who_weekly$Date <- as.Date(who_weekly$Date)

comparison <- filter(who_weekly, Date <= max(sl_large$Date)) %>%
    left_join(district_weekly) %>%
    na.omit()
comparison$Date <- as.Date(comparison$Date)

p <- ggplot(comparison, aes(Date,incid)) + geom_point(size = 0.5,
                                                      col = "blue") 
p <- p + facet_wrap(~district, scales = "free_y")
p <- p + geom_line(aes(y = `0.5`))
p <- p + geom_ribbon(aes(ymin = `0.025`,
                         ymax = `0.975`,
                         group = 1), alpha = 0.5)
p <- p + theme_classic()
p

```

