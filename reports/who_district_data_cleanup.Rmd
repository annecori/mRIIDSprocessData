---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
title: Collate and clean-up data from WHO
author:
- name: Sangeeta Bhatia
  affiliation: Imperial College London
abstract: 
keywords: 
date: "`r Sys.Date()`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
spacing: double
bibliography: 
biblio-style: apsr
endnote: no
---

```{r setup, eval = TRUE}
library(dplyr)
library(magrittr)
library(stringr)
library(ggplot2)
```
WHO has published weekly incidence data on its website for each country affected
by Ebola e.g., see
(here)[http://apps.who.int/gho/data/node.ebola-sitrep.ebola-country-SLE?lang=en].

This data set needs to be downloaded and cleaned-up before it can be
used in any analysis.

```{r flags, eval = TRUE}
download <- FALSE
process  <- TRUE

```

```{r who_download, eval = download}
start <- lubridate::dmy("12-11-2014")
end   <- lubridate::dmy("11-05-2016")
weekly <- seq(from = start, to = end, by = "1 week")
url_prefix <- "http://apps.who.int/gho/athena/xmart/xmart.csv?target=EBOLA_MEASURE/CASES&profile=crosstable&filter=LOCATION:*;COUNTRY:SLE;INDICATOR_TYPE:SITREP_NEW;DATAPACKAGEID:"
url_suffix <- ";SEX:-&x-sideaxis=LOCATION;EBOLA_DATA_SOURCE;INDICATOR_TYPE;CASE_DEFINITION&x-topaxis=COUNTRY;EPI_WEEK&x-collapse=true"
url <- paste0(url_prefix, weekly, url_suffix)
weekly_data <- lapply(url, function(u) data.table::fread(u))
names(weekly_data) <- paste0("who_sl_", weekly, ".csv")
lapply(names(weekly_data), function(name) readr::write_csv(x = weekly_data[[name]], path = here::here("data/CaseCounts/raw", name)))

```

## Clean-up

```{r}
infile <- "data/CaseCounts/raw/who_sl_2014-11-26.csv"
sl_26_nov <- readr::read_csv(infile)

```

The first 4 columns are separated by semi-colons rather than comma. 
Separate the first column into 4 separate columns.

```{r}
sl_26_nov <- tidyr::separate(data = sl_26_nov,
                             col = `Location; Ebola data source; Indicator type; Case definition`,
                             sep = ";",
                             into = c("location", "data_source", "type", "case"))
```

Next get rid of the country name is the column names.

```{r}
colnames(sl_26_nov) <- stringr::str_remove_all(colnames(sl_26_nov),
                                               "Sierra Leone; ")

```

Now reshape the data frame so that time (which currently runs down the
columns) runs down rows.

```{r}
sl_26_nov <- tidyr::gather(sl_26_nov, "week", "new_cases", 5:51)
```
