---
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: false
    fig_caption: true
    latex_engine: pdflatex
title: Analysis of Ebola data from HealthMap
author:
- name: Sangeeta Bhatia
  affiliation: Imperial College London
date: "`r format(Sys.time(), '%d %B, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
spacing: double
bibliography: 
biblio-style: apsr
endnote: no
params:
  pow_dist : 1
  t.proj : 35
  n.sim : 1000
  n.dates.sim : 28
  p.stay: 1
---

# Introduction

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=6, echo=FALSE, warning=FALSE, message=FALSE, fig.path = "figures/")

```


```{r setup}
library(magrittr)
library(ggplot2)
library(dplyr)
library(EpiEstim)
devtools::load_all()

pow_dist    <- params$pow_dist
t.proj      <- params$t.proj
n.sim       <- params$n.sim
n.dates.sim <- params$n.dates.sim
p.stay      <- params$p.stay

```

```{r hm_wafrica, eval = TRUE}

w.africa       <- c("Guinea", "Liberia", "Sierra Leone")

```
# Parameters for Ebola and Reproduction Number Estimation

Culled from [literature](http://www.nejm.org/doi/suppl/10.1056/NEJMc1414992/suppl_file/nejmc1414992_appendix.pdf)


```{r ebola_params}

mean_SI     <- 14.2
CV_SI       <- 9.6 / 14.2
SItrunc     <- 40
SI_Distr    <- sapply(0:SItrunc, function(e) DiscrSI(e, mean_SI, mean_SI * CV_SI))
SI_Distr    <- SI_Distr / sum(SI_Distr)
time_window <- 7 * 7

```

# Gravity model parameters

```{r gm_params}

pow_N_to <- pow_N_from <- 1
K        <- 1

```

# Wide Data load

Read in cleaned-up and wide formatted data. 

```{r hm_dataload, eval = TRUE}
hm_wide <- here::here("data",
                      "CaseCounts/processed/HealthMap_Ebola_wide.csv")
by.location_incid <- readr::read_csv(hm_wide)

```
We now use the incidence count to estimate reproduction number.

```{r hm_restim, eval = TRUE}

start     <- 1:(length(by.location_incid$Date) - time_window)
end       <- start + time_window
end.dates <- by.location_incid[end, "Date"]
r.estim   <- by.location_incid %>%
                   select(-Date) %>%
    plyr::alply(2, .dims = TRUE, function(incid) {
                                                 I <- pull(incid, 1)
                                                 res <- EstimateR(I, T.Start = start , T.End = end,
                                                                  method = "NonParametricSI",
                                                                  SI.Distr = SI_Distr,
                                                                  plot = FALSE ,
                                                                  CV.Posterior = 1 ,
                                                                  Mean.Prior = 1 ,
                                                                  Std.Prior = 0.5)
                                                 res$R %<>% cbind(Date = end.dates)
                                                 return(res$R)})

```

```{r write_r, eval = FALSE}

lapply(names(r.estim), function(country) {
    R <- r.estim[[country]]
    outfile <- paste0("output/", country, "-R.csv")
    write.csv(R, file = outfile, row.names = F, quote = F)
})


```

```{r hm_r_viz, eval = TRUE}

lapply(names(r.estim), function(country) {
    R <- r.estim[[country]]
    p <- ggplot(R, aes(Date)) +
        geom_ribbon(aes(ymin = `Quantile.0.025(R)`,
                        ymax = `Quantile.0.975(R)`),
                    fill = "grey70") +
         geom_line(aes(y =  `Mean(R)`)) +
        theme_minimal() + ylab("Reproduction Number R")
    ggsave(file = paste0("figures/", country, "-R.png"), p)
})

```
We assume that the reproduction number remains unchanged for the time
period over which we wish to project. For each location, distribution of
r_t at t.proj is r_t over the next n.days.sim.


```{r rjt, eval = TRUE}

r.j.t <- r.estim %>%
           lapply(function(R){
                     cutoff <- which(R$Date %in% by.location_incid[t.proj, "Date"])
                     shape  <- R[cutoff, "Mean(R)"]^2 / R[cutoff, "Std(R)"]^2
                     scale  <- R[cutoff, "Std(R)"]^2 / R[cutoff, "Mean(R)"]
                     return(rgamma(n.sim, shape = shape,
                                          scale = scale))}) %>% data.frame




```

Determine the flow matrix for the countries of interest only.

```{r}


adm0_centroids <- here::here("data", "Geography/GravityModel/raw/adm0_centroids.tsv") %>%
                   read.csv(stringsAsFactors = FALSE, sep = "\t", header = FALSE) %>%
                   filter(V1 %in% w.africa)
names(adm0_centroids) <- c("country", "id", "lon", "lat", "pop")
flow.matrix           <- flow_matrix(longitude = adm0_centroids[, "lon"],
                                     latitude  = adm0_centroids[, "lat"],
                                     population = adm0_centroids[, "pop"],
                                     place.names = adm0_centroids[, "country"],
                                     model = "gravity",
                                     K = K, pow_N_from = pow_N_from,
                                     pow_N_to = pow_N_to, pow_dist = pow_dist)


## Relative risk
relative.risk <- flow.matrix / rowSums(flow.matrix, na.rm=TRUE)

## matrix characterising the population movement between geographical units
p.stay      <- 0.99 # this can be a vector
p.movement  <- probability_movement(relative.risk, p.stay)

```


At this point, all the pieces are in place. by.location_incid contains the incidence count
r.j.t contains the estimates of reproduction numbers.
p.movement conatins the probabilities.
SI_Distr is the serial interval distribution.
The model is: lambda.j.t = p.movement * (incidence * r_t) * serial_interval
taking care of the dimensions of course. Now divide the dataset into
training and validation sets.

We will now split our data into training and validation sets.

```{r hm_split, eval = TRUE}

training   <- by.location_incid[1:t.proj, ]
validation <- by.location_incid[(t.proj + 1):nrow(by.location_incid), ]

```

```{r hm_projection, eval = TRUE}

incidence.count <- select(training, -Date)
incid           <- as.matrix(incidence.count)
dates.all       <- training$Date %>%
                       c(seq(max(.) + 1, length.out = n.dates.sim, by = 1))
t.max           <- nrow(incidence.count) + n.dates.sim - 1

daily.projections <- plyr::alply(r.j.t, 1, function(r.t){
                                    r.t   <- as.matrix(r.t)
                                    out   <- project(incid, r.t, SI_Distr,
                                                     p.movement, n.dates.sim)

                                    incidence.proj  <- rbind(incidence.count, out)
                                    incidence.proj %<>% cbind(Date = dates.all)
                                    return(incidence.proj[(nrow(incidence.count) + 1):t.max, ])})




```


```{r hm_plotslist, eval = TRUE}

weekly.available <- c(training    = list(training),
                       validation = list(validation)) %>%
                       lapply(daily.to.weekly) %>%
                       bind_rows(.id = "Category")

weekly.projections <- lapply(daily.projections, daily.to.weekly) %>% bind_rows(.)


projections_distr <- projection_quantiles(weekly.projections)
outfile <- paste0("hm_summary_projections_", p.stay, "_", pow_dist, "_", t.proj, ".csv")
outfile <- here::here("output", outfile)
write.csv(projections_distr, file = outfile, row.names = F, quote = F)

outfile <- paste0("hm_summary_projections_", p.stay, "_", pow_dist, "_", t.proj, ".png")
outfile <- here::here("output", outfile)


```
